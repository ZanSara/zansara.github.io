---
title: "ODSC East: LLMs that think - Demystifying Reasoning Models"
date: 2025-05-14
author: "ZanSara"
featuredImage: "/talks/2025-05-13-odsc-east-reasoning-models.png"
aliases:
 - /talks/2025-05-14-odsc-east-reasoning-models
---

[Announcement](https://odsc.com/speakers/llms-that-think-demystifying-reasoning-models/), [teaser article](https://www.zansara.dev/posts/2025-05-12-beyond-hype-reasoning-models/), [slides](https://drive.google.com/file/d/1Gmxx2G-H0aozBZtACCvGIqJNgybXB716/view?usp=sharing).
All resources can also be found in 
[my archive](https://drive.google.com/drive/folders/1Iy_mJr7MYdrbb-W-g1U38gkPBjrV8dGu?usp=drive_link).

---

At [ODSC East 2025](https://odsc.com/boston/) I talked about reasoning models: what they are, what they aren't, how they work and when to use them. Is OpenAI's o4 AGI? Is it an AI Agent? Or is it just a glorified chain-of-thought prompt under the hood? To answer these questions, I classified LLMs into a small "taxonomy" based on the post-training steps they go through, in order to highlight how reasoning models differ qualitatively from their predecessors just like instruction-tuned models were not simple text-completion models with a better prompt. I also covered the effect of increasing the reasoning effort of the model, clarifying when it's useful and when it can lead to overthinking.